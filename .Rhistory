print("No Multicollinear"))
# multiResults <- c(multiResults, res)
}
for (i in 1:dim(sonarComb)[2]) {
browser()
multicolRes$vs[i] <- paste0(sonarComb[1,i], " & ", sonarComb[2,i])
multicolRes$cor[i] <- cor.test(sonar[,sonarComb[1,i]], sonar[,sonarComb[2,i]])
multicolRes$res[i] <- ifelse(corTest$p.value < Alpha,
print("Multicollinear"),
print("No Multicollinear"))
# multiResults <- c(multiResults, res)
}
multicolRes$vs
multicolRes$vs[1]
multicolRes$vs[1] <- 1
multicolRes <- data.frame(row.names = c("vs", "cor", "res"))
multicolRes
multicolRes <- data.frame(colnames = c("vs", "cor", "res"))
multicolRes
multicolRes <- data.frame(vs,cor,res)
multicolRes <- data.frame(vs = 0, cor = 0, res = 0)
multicolRes
multicolRes$vs[2] <- 1
multicolRes <- data.frame(vs = 1:dim(sonarComb)[2],
cor = 1:dim(sonarComb)[2],
res = 1:dim(sonarComb)[2])
multicolRes
dim(sonarComb)[2]
sonarComb <- combn(colnames(sonar[,-61]), 2)
Alpha <- 0.05
multicolRes <- data.frame(vs = 1:dim(sonarComb)[2],
cor = 1:dim(sonarComb)[2],
res = 1:dim(sonarComb)[2])
for (i in 1:dim(sonarComb)[2]) {
multicolRes$vs[i] <- paste0(sonarComb[1,i], " & ", sonarComb[2,i])
multicolRes$cor[i] <- cor.test(sonar[,sonarComb[1,i]], sonar[,sonarComb[2,i]])
multicolRes$res[i] <- ifelse(corTest$p.value < Alpha,
print("Multicollinear"),
print("No Multicollinear"))
# multiResults <- c(multiResults, res)
}
sonarComb <- combn(colnames(sonar[,-61]), 2)
Alpha <- 0.05
multicolRes <- data.frame(vs = 1:dim(sonarComb)[2],
cor = 1:dim(sonarComb)[2],
res = 1:dim(sonarComb)[2])
for (i in 1:dim(sonarComb)[2]) {
multicolRes$vs[i] <- paste0(sonarComb[1,i], " & ", sonarComb[2,i])
corTest <- cor.test(sonar[,sonarComb[1,i]], sonar[,sonarComb[2,i]])
multicolRes$cor[i] <- corTest$p.value
multicolRes$res[i] <- ifelse(corTest$p.value < Alpha,
"Multicollinear",
"No Multicollinear")
# multiResults <- c(multiResults, res)
}
multicolRes
table(multicolRes$vs, multicolRes$vs)
table(multicolRes$res, multicolRes$vs)
table(multicolRes$res)
multicolRes$cor[i] <- corTest$p.value
multicolRes
for (i in 1:dim(sonarComb)[2]) {
multicolRes$vs[i] <- paste0(sonarComb[1,i], " & ", sonarComb[2,i])
corTest <- cor.test(sonar[,sonarComb[1,i]], sonar[,sonarComb[2,i]])
multicolRes$cor[i] <- corTest$p.value
multicolRes$res[i] <- ifelse(corTest$p.value < Alpha,
"Yes",
"No")
# multiResults <- c(multiResults, res)
}
multicolRes
table(multicolRes$res)
multicolRes[, multicolRes$res == "No"]
multicolRes[,multicolRes$res == "No"]
multicolRes[multicolRes$res == "No",]
set.seed(1)
idx <- initial_split(sonar, prop = 0.8, strata = type)
sonar_train <- training(idx)
sonar_test <- testing(idx)
prop.table(table(sonar_train$type)) # Check train dataset proportion after split
prop.table(table(sonar_test$type)) # Check test dataset proportion after split
prop.table(table(sonar_train$type)) # Check train dataset proportion after split
prop.table(table(sonar_test$type)) # Check test dataset proportion after split
set.seed(1)
idx <- initial_split(sonar, prop = 0.8, strata = type)
sonar_train <- training(idx)
sonar_test <- testing(idx)
prop.table(table(sonar_train$type)) # Check train dataset proportion after split
prop.table(table(sonar_test$type)) # Check test dataset proportion after split
# Split the predictors and the target of train dataset for KNN model usage
X_train <- sonar_train[,-ncol(sonar_train)]
y_train <- sonar_train[,ncol(sonar_train)]
# Split the predictors and the target of test dataset for KNN model usage
X_test <- sonar_test[,-ncol(sonar_test)]
y_test <- sonar_test[,ncol(sonar_test)]
model_log <- glm(formula = type ~ ., data = sonar_train, family = "binomial")
summary(model_log)
exp(8.595e+02)
exp(-9.118e+02)
exp(6.780e+00)
1.070e+03
8.595e+02
X_train.scaled <- scale(x = X_train)
X_test.scaled <- scale(x = X_test,
center = attr(X_train.scaled, "scaled:center"),
scale = attr(X_train.scaled, "scaled:scale"))
K <- sqrt(nrow(X_train))
K
round(K)
predict_knn <- knn(train = X_train.scaled, test = X_test.scaled, cl = y_train, k = round(K))
iconfusionMatrix(data = predict_knn, reference = y_test)
library(tidyverse) # for data wrangling
library(plotly) # for plotting using plotly style
library(caret) # for confusion matrix
library(gtools) # for converting log of odds to probs
library(PerformanceAnalytics) # for pair plotting
library(car) # for executing VIF test
library(rsample) # for splitting dataset into train and test with controlled proportion
library(class) # for KNN
confusionMatrix(data = predict_knn, reference = y_test)
predict_knn <- knn(train = X_train.scaled, test = X_test.scaled, cl = y_train, k = 14)
confusionMatrix(data = predict_knn, reference = y_test)
predict_knn <- knn(train = X_train.scaled, test = X_test.scaled, cl = y_train, k = 21)
confusionMatrix(data = predict_knn, reference = y_test)
predict_knn <- knn(train = X_train.scaled, test = X_test.scaled, cl = y_train, k = 101)
confusionMatrix(data = predict_knn, reference = y_test)
predict_knn <- knn(train = X_train.scaled, test = X_test.scaled, cl = y_train, k = 161)
confusionMatrix(data = predict_knn, reference = y_test)
predict_knn <- knn(train = X_train.scaled, test = X_test.scaled, cl = y_train, k = 19)
confusionMatrix(data = predict_knn, reference = y_test)
predict_log <- predict(object = model_log, newdata = sonar_test, type = "response")
sonar_test$ypred_prob <- predict_log
sonar_test$ypred_label <- ifelse(sonar_test$ypred_prob > 0.5, "R", "M")
# negative class is M
# positive class is R
# since at the beginning, R automatically sets "M" as the first as class, meaning the negative class
confusionMatrix(data = as.factor(sonar_test$ypred_label), reference = y_test, positive = "R")
confusionMatrix(data = as.factor(sonar_test$ypred_label), reference = y_test, positive = "R")
confusionMatrix(data = predict_knn, reference = y_test, positive = "R")
table(sonar$type, sonar$energy50)
plot(table(sonar$type, sonar$energy50))
table(sonar$type, sonar$energy50)
boxplot(table(sonar$type, sonar$energy50))
library(ROCR)
df_ <- data.frame("prediction" = predict_log,
"trueclass" = as.numeric(y_test == "R"))
df__roc <- prediction(df_$prediction, df_$trueclass)
plot(performance(df__roc, "tpr", "fpr"))
auc <- ROCR::performance(prediction.obj = df__roc, "auc")
auc@y.values[[1]]
predict_knn
2%%3
2%%2
2%%2
2%%1
2%%0
5%%4
10%%2
11%%2
13%%2
optK <- sapply(1:nrow(X_train), function(x) {ifelse(x%%2 == 1, T, F)})
optK
1:nrow(X_train)[optK]
1:nrow(X_train)
1:nrow(X_train)[optK]
optK
data.frame(1:nrow(X_train))
data.frame(1:nrow(X_train))[optK,]
optK <- sapply(1:nrow(X_train)-1, function(x) {ifelse(x%%2 == 1, T, F)})
data.frame(1:nrow(X_train))[optK,]
optK
1:nrow(X_train)-1
1:(nrow(X_train)-1)
optK <- sapply(1:(nrow(X_train)-1), function(x) {ifelse(x%%2 == 1, T, F)})
data.frame(1:nrow(X_train))[optK,]
optK
1:(nrow(X_train)-1)
optK
data.frame(1:nrow(X_train))[optK,]
data.frame(1:nrow(X_train)-1)[optK,]
data.frame(1:(nrow(X_train)-1))[optK,]
optK <- sapply(1:nrow(X_train), function(x) {ifelse(x%%2 == 1, T, F)})
data.frame(1:(nrow(X_train)-1))[optK,]
optK <- sapply(1:(nrow(X_train)-1), function(x) {ifelse(x%%2 == 1, T, F)})
data.frame(1:(nrow(X_train)-1))[optK,]
a <- confusionMatrix(data = predict_knn, reference = y_test, positive = "R")
a$positive
a$table
a$overall
a$overall$Accuracy
a$Accuracy
a$accuracy
a$byClass
confusionMatrix(data = predict_knn, reference = y_test, positive = "R")
table(predict_knn, y_test)
predict_knn == "M" & y_test == "M"
table(predict_knn, y_test)
sum(predict_knn == "M" & y_test == "M")
table(predict_knn, y_test)
sum(predict_knn == "R" & y_test == "R")
table(predict_knn, y_test)
length(y_test)
table(predict_knn, y_test)
(sum(predict_knn == "M" & y_test == "M") + sum(predict_knn == "R" & y_test == "R"))/length(y_test)
Accuracy(y_pred = predict_knn, y_true = y_train)
MLmetrics::Accuracy(y_pred = predict_knn, y_true = y_train)
predict_knn
y_train
MLmetrics::Accuracy(y_pred = predict_knn, y_true = y_test)
library(MLmetrics)
oddK_idx <- sapply(1:(nrow(X_train)-1), function(x) {ifelse(x%%2 == 1, T, F)})
optK <- data.frame(1:(nrow(X_train)-1))[oddK_idx,]
optKNN <- data.frame(K = 1:length(optK), acc = 1:length(optK))
for (i in 1:length(optK)) {
predknn <- knn(train = X_train.scaled, test = X_test.scaled, cl = y_train, k = optK[i])
optKNN$K[i] <- optK[i]
optKNN$acc[i] <- Accuracy(predknn, y_test)
}
plot(x = optKNN$K, y = optKNN$acc)
optKNN[max(optKNN$acc),]
max(optKNN$acc)
optKNN[optKNN$acc == max(optKNN$acc),]
optKNN %>% ggplot(aes(x = K,
y = acc)) +
geom_line(color = "blue")
maxAcc <- optKNN[optKNN$acc == max(optKNN$acc),]
optKNN %>% ggplot(aes(x = K,
y = acc)) +
geom_line(color = "blue") +
geom_point(aes(data = maxAcc,
x = K,
y = acc))
optKNN$acc == max(optKNN$acc)
library(MLmetrics)
oddK_idx <- sapply(1:(nrow(X_train)-1), function(x) {ifelse(x%%2 == 1, T, F)})
optK <- data.frame(1:(nrow(X_train)-1))[oddK_idx,]
optKNN <- data.frame(K = 1:length(optK), acc = 1:length(optK))
for (i in 1:length(optK)) {
predknn <- knn(train = X_train.scaled, test = X_test.scaled, cl = y_train, k = optK[i])
optKNN$K[i] <- optK[i]
optKNN$acc[i] <- Accuracy(predknn, y_test)
}
maxAcc <- optKNN[optKNN$acc == max(optKNN$acc),]
optKNN %>% ggplot(aes(x = K,
y = acc)) +
geom_line(color = "blue") +
geom_point(data = maxAcc, aes(x = K,
y = acc))
# (x = optKNN$K, y = optKNN$acc)
optKNN %>% ggplot(aes(x = K,
y = acc)) +
geom_line(color = "blue") +
geom_point(data = maxAcc, aes(x = K,
y = acc)) +
geom_text(data = maxAcc, aes(label = K))
optKNN %>% ggplot(aes(x = K,
y = acc)) +
geom_line(color = "blue") +
geom_point(data = maxAcc, aes(x = K,
y = acc)) +
geom_text(data = maxAcc, aes(label = as.character(K)))
optKNN %>% ggplot(aes(x = K,
y = acc)) +
geom_line(color = "blue") +
geom_point(data = maxAcc, aes(x = K,
y = acc)) +
geom_text(data = maxAcc, aes(label = max(acc)))
optKNN %>% ggplot(aes(x = K,
y = acc)) +
geom_line(color = "blue") +
geom_point(data = maxAcc, aes(x = K,
y = acc)) +
geom_text(data = maxAcc, aes(label = c(acc, K)))
optKNN %>% ggplot(aes(x = K,
y = acc)) +
geom_line(color = "blue") +
geom_point(data = maxAcc, aes(x = K,
y = acc)) +
geom_text(data = maxAcc, aes(label = acc))
maxAcc
label <- paste0(maxAcc$acc, " when K: ", maxAcc$K)
library(MLmetrics)
oddK_idx <- sapply(1:(nrow(X_train)-1), function(x) {ifelse(x%%2 == 1, T, F)})
optK <- data.frame(1:(nrow(X_train)-1))[oddK_idx,]
optKNN <- data.frame(K = 1:length(optK), acc = 1:length(optK))
for (i in 1:length(optK)) {
predknn <- knn(train = X_train.scaled, test = X_test.scaled, cl = y_train, k = optK[i])
optKNN$K[i] <- optK[i]
optKNN$acc[i] <- Accuracy(predknn, y_test)
}
maxAcc <- optKNN[optKNN$acc == max(optKNN$acc),]
label <- paste0(maxAcc$acc, " when K: ", maxAcc$K)
optKNN %>% ggplot(aes(x = K,
y = acc)) +
geom_line(color = "blue") +
geom_point(data = maxAcc, aes(x = K,
y = acc)) +
geom_text(data = maxAcc, aes(label = label))
# (x = optKNN$K, y = optKNN$acc)
optKNN %>% ggplot(aes(x = K,
y = acc)) +
geom_line(color = "blue") +
geom_point(data = maxAcc, aes(x = K,
y = acc)) +
geom_text(data = maxAcc, aes(label = label), position = 1)
optKNN %>% ggplot(aes(x = K,
y = acc)) +
geom_line(color = "blue") +
geom_point(data = maxAcc, aes(x = K,
y = acc)) +
geom_label(data = maxAcc, aes(label = label), position = "right", label.size = 0.1)
optKNN %>% ggplot(aes(x = K,
y = acc)) +
geom_line(color = "blue") +
geom_point(data = maxAcc, aes(x = K,
y = acc)) +
geom_label(data = maxAcc, aes(label = label), label.size = 0.1)
optKNN %>% ggplot(aes(x = K,
y = acc)) +
geom_line(color = "blue") +
geom_point(data = maxAcc, aes(x = K,
y = acc)) +
geom_label(data = maxAcc, aes(label = label), position = "dodge", label.size = 0.1)
optKNN %>% ggplot(aes(x = K,
y = acc)) +
geom_line(color = "blue") +
geom_point(data = maxAcc, aes(x = K,
y = acc)) +
geom_label(data = maxAcc, aes(label = label), position = position_dodge(0.1), label.size = 0.1)
optKNN %>% ggplot(aes(x = K,
y = acc)) +
geom_line(color = "blue") +
geom_point(data = maxAcc, aes(x = K,
y = acc)) +
geom_label(data = maxAcc, aes(label = label), position = position_dodge(1), label.size = 0.1)
optKNN %>% ggplot(aes(x = K,
y = acc)) +
geom_line(color = "blue") +
geom_point(data = maxAcc, aes(x = K,
y = acc)) +
geom_label(data = maxAcc, aes(label = label), position = position_dodge(10), label.size = 0.1)
optKNN %>% ggplot(aes(x = K,
y = acc)) +
geom_line(color = "blue") +
geom_point(data = maxAcc, aes(x = K,
y = acc)) +
geom_label(data = maxAcc, aes(label = label), position = position_dodge(30), label.size = 0.1)
optKNN %>% ggplot(aes(x = K,
y = acc)) +
geom_line(color = "blue") +
geom_point(data = maxAcc, aes(x = K,
y = acc)) +
geom_label(data = maxAcc, aes(label = label), position = position_dodge(70), label.size = 0.1)
library(MLmetrics)
oddK_idx <- sapply(1:(nrow(X_train)-1), function(x) {ifelse(x%%2 == 1, T, F)})
optK <- data.frame(1:(nrow(X_train)-1))[oddK_idx,]
optKNN <- data.frame(K = 1:length(optK), acc = 1:length(optK))
for (i in 1:length(optK)) {
predknn <- knn(train = X_train.scaled, test = X_test.scaled, cl = y_train, k = optK[i])
optKNN$K[i] <- optK[i]
optKNN$acc[i] <- Accuracy(predknn, y_test)
}
maxAcc <- optKNN[optKNN$acc == max(optKNN$acc),]
label <- paste0(round(maxAcc$acc, 2), " when K: ", maxAcc$K)
optKNN %>% ggplot(aes(x = K,
y = acc)) +
geom_line(color = "blue") +
geom_point(data = maxAcc, aes(x = K,
y = acc)) +
geom_label(data = maxAcc, aes(label = label), position = position_dodge(70), label.size = 0.1)
# (x = optKNN$K, y = optKNN$acc)
optKNN %>% ggplot(aes(x = K,
y = acc)) +
geom_line(color = "blue") +
geom_point(data = maxAcc, aes(x = K,
y = acc)) +
geom_label(data = maxAcc, aes(label = label), position = position_dodge(10), label.size = 0.1)
optKNN %>% ggplot(aes(x = K,
y = acc)) +
geom_line(color = "blue") +
geom_point(data = maxAcc, aes(x = K,
y = acc)) +
geom_label(data = maxAcc, aes(label = label), position = position_dodge(15), label.size = 0.1)
optKNN %>% ggplot(aes(x = K,
y = acc)) +
geom_line(color = "blue") +
geom_point(data = maxAcc, aes(x = K,
y = acc)) +
geom_label(data = maxAcc, aes(label = label), position = position_dodge(17), label.size = 0.1)
library(MLmetrics)
oddK_idx <- sapply(1:(nrow(X_train)-1), function(x) {ifelse(x%%2 == 1, T, F)})
optK <- data.frame(1:(nrow(X_train)-1))[oddK_idx,]
optKNN <- data.frame(K = 1:length(optK), acc = 1:length(optK))
for (i in 1:length(optK)) {
predknn <- knn(train = X_train.scaled, test = X_test.scaled, cl = y_train, k = optK[i])
optKNN$K[i] <- optK[i]
optKNN$acc[i] <- Accuracy(predknn, y_test)
}
maxAcc <- optKNN[optKNN$acc == max(optKNN$acc),]
label <- paste0(round(maxAcc$acc, 2), " when K = ", maxAcc$K)
optKNN %>% ggplot(aes(x = K,
y = acc)) +
geom_line(color = "blue") +
geom_point(data = maxAcc, aes(x = K,
y = acc)) +
geom_label(data = maxAcc, aes(label = label), position = position_dodge(17), label.size = 0.05)
# (x = optKNN$K, y = optKNN$acc)
optKNN %>% ggplot(aes(x = K,
y = acc)) +
geom_line(color = "blue") +
geom_point(data = maxAcc, aes(x = K,
y = acc)) +
geom_label(data = maxAcc, aes(label = label), position = position_dodge(18), label.size = 0.05)
optKNN %>% ggplot(aes(x = K,
y = acc)) +
geom_line(color = "blue") +
geom_point(data = maxAcc, aes(x = K,
y = acc)) +
geom_label(data = maxAcc, aes(label = label), position = position_dodge(20), label.size = 0.05)
library(MLmetrics)
oddK_idx <- sapply(1:(nrow(X_train)-1), function(x) {ifelse(x%%2 == 1, T, F)})
optK <- data.frame(1:(nrow(X_train)-1))[oddK_idx,]
optKNN <- data.frame(K = 1:length(optK), acc = 1:length(optK))
for (i in 1:length(optK)) {
predknn <- knn(train = X_train.scaled, test = X_test.scaled, cl = y_train, k = optK[i])
optKNN$K[i] <- optK[i]
optKNN$acc[i] <- Accuracy(predknn, y_test)
}
maxAcc <- optKNN[optKNN$acc == max(optKNN$acc),]
label <- paste0(round(maxAcc$acc, 2), " when K = ", maxAcc$K)
optKNN %>% ggplot(aes(x = K,
y = acc)) +
geom_line(color = "blue") +
geom_point(data = maxAcc, aes(x = K,
y = acc)) +
geom_label(data = maxAcc, aes(label = label), position = position_dodge(20), label.size = 0.05) +
labs(title = "No of K vs Accuracy in KNN prediction",
x = "Number of Ks",
y = "Accuracy")
table(sonar$type, sonar$energy50)
table(sonar$type, sonar$energy49)
table(sonar$type, sonar$energy51)
model_log
model_log <- glm(formula = type ~ ., data = sonar_train, family = "binomial", maxit = 50)
model_log <- glm(formula = type ~ ., data = sonar_train, family = "binomial")#, maxit = 50)
model_log <- glm(formula = type ~ ., data = sonar_train, family = "binomial", maxit = 30)
model_log <- glm(formula = type ~ ., data = sonar_train, family = "binomial", maxit = 27)
model_log <- glm(formula = type ~ ., data = sonar_train, family = "binomial", maxit = 28)
model_log <- glm(formula = type ~ ., data = sonar_train, family = "binomial", maxit = 29)
model_log <- glm(formula = type ~ ., data = sonar_train, family = "binomial", maxit = 30)
summary(model_log)
table(sonar$energy51, sonar$type)
table(sonar_train$energy51, sonar_train$type)
sonar_train
table(sonar_train$type)
sample(nrow(sonar_train), nrow(sonar_train))
ranIdx <- sample(nrow(sonar_train), nrow(sonar_train))
sonar_train[ranIdx,]
set.seed(1)
ranIdx <- sample(nrow(sonar_train), nrow(sonar_train))
sonar_train <- sonar_train[ranIdx,]
rownames(sonar_train) <- NULL
set.seed(2)
ranIdx <- sample(nrow(sonar_test), nrow(sonar_test))
sonar_test <- sonar_test[ranIdx,]
rownames(sonar_test) <- NULL
sonar_train
sonar_test
set.seed(1)
idx <- initial_split(sonar, prop = 0.8, strata = type)
sonar_train <- training(idx)
sonar_test <- testing(idx)
prop.table(table(sonar_train$type)) # Check train dataset proportion after split
prop.table(table(sonar_test$type)) # Check test dataset proportion after split
# Split the predictors and the target of train dataset for KNN model usage
X_train <- sonar_train[,-ncol(sonar_train)]
y_train <- sonar_train[,ncol(sonar_train)]
# Split the predictors and the target of test dataset for KNN model usage
X_test <- sonar_test[,-ncol(sonar_test)]
y_test <- sonar_test[,ncol(sonar_test)]
sonar_test
set.seed(1)
ranIdx <- sample(nrow(sonar_train), nrow(sonar_train))
sonar_train <- sonar_train[ranIdx,]
rownames(sonar_train) <- NULL
set.seed(2)
ranIdx <- sample(nrow(sonar_test), nrow(sonar_test))
sonar_test <- sonar_test[ranIdx,]
rownames(sonar_test) <- NULL
model_log <- glm(formula = type ~ ., data = sonar_train, family = "binomial", maxit = 30)
model_log <- glm(formula = type ~ energy1, data = sonar_train, family = "binomial")
summary(model_log)
predict_log <- predict(object = model_log, newdata = sonar_test, type = "response")
sonar_test$ypred_prob <- predict_log
sonar_test$ypred_label <- ifelse(sonar_test$ypred_prob > 0.5, "R", "M")
# negative class is M
# positive class is R
# since at the beginning, R automatically sets "M" as the first as class, meaning the negative class
confusionMatrix(data = as.factor(sonar_test$ypred_label), reference = y_test, positive = "R")
model_log <- glm(formula = type ~ energy1 + energy2, data = sonar_train, family = "binomial")
summary(model_log)
model_log <- glm(formula = type ~ energy1 + energy2 + energy3, data = sonar_train, family = "binomial")
model_log <- glm(formula = type ~ energy1 + energy2 + energy3 + energy50, data = sonar_train, family = "binomial")
summary(model_log)
model_log <- glm(formula = type ~ energy1, data = sonar_train, family = "binomial")
summary(model_log)
model_log <- glm(formula = type ~ energy1 + energy2 + energy3 + energy50, data = sonar_train, family = "binomial")
summary(model_log)
model_log <- glm(formula = type ~ energy1 + energy2, data = sonar_train, family = "binomial")
summary(model_log)
model_log <- glm(formula = type ~ energy2, data = sonar_train, family = "binomial")
summary(model_log)
